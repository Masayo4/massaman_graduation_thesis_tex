\chapter{実装}
\label{chap:developing}
本章では, Delta Smile Facial Survey Analyzer の実装部分について説明する.
まずユーザーインターフェースの実装について説明し, システム全体の画面遷移の流れを最初に示す.
次にデータ収集機能の各モジュールの実装について整理し, データ分析機能の各モジュールの実装について
説明し,まとめる.

\section{ユーザーインターフェースの実装}
本システムではおよそ3分程度で一連のデータ収集機能のシステム処理を行う.
開発言語はpythonを使用し, バージョンは3.6.1 を使用した.
実行コマンドは以下のように行う. mode\_num は0を引数に指定するとユーザーからのデータを収集し,
1を指定すると既存の動画に対して処理を行いデータ形成を行うことできる.

\begin{itemize}
\item 実行コマンド
\begin{lstlisting}
$ python dsfsa.py mode_num
\end{lstlisting}
%複数の時は以下のように
%\item 実行コマンド
%\begin{lstlisting}
%＄ python dsfsa.py mode_num
%\end{lstlisting}
\end{itemize}

ユーザーに見せるシーンとして全部で8種類のシーンが存在する.
各シーンは全てオープンソースのOpenCVを使用して, ディスプレイeizo sx2761wに表示をしている.
それぞれの表示内容, 役割について以下に述べる.

\subsection{ユーザーインターフェースシーン1}
図\ref{fig:seen1}のシーン1はシステムを起動した最初のシーンである.
実験の際に, 個人情報である表情のデータを使うため, ユーザーの同意が必要である.
パソコンのReturnキーを一回入力することで実験, データ提供への同意を得るように実装を行った.

\subsection{ユーザーインターフェースシーン2}
図\ref{fig:seen2}のシーン2はユーザーの基本情報を収集するためのシーンである.
基本情報として, 性別と年齢を何十歳の形で入力をする.
入力したデータは.txtファイルとしてユーザーごとのフォルダーに保存するようにした.

\subsection{ユーザーインターフェースシーン3}
図\ref{fig:seen2}のシーン2にて,基本情報を入力したのちに, 図\ref{fig:seen3}のシーン3へ自動で遷移する.
このシーンでは実際にユーザーの映像がwebカメラ,Logicool C920r の映像が映し出される.
遷移と同時にカメラに映る一番大きな顔をユーザーの顔として認識をしトラッキングを行っている.

\subsection{ユーザーインターフェースシーン4}
図\ref{fig:seen4}のシーン4では, 図\ref{fig:seen3}のシーン3にて, 笑顔が検出された場合にはユーザーの笑顔が検出されていることを知らせる
小さいウィンドウが表示され, 検出した口元に緑色の長方形が描画されるようになっている.

\subsection{ユーザーインターフェースシーン5}
図\ref{fig:seen4}のシーン4にて, 笑顔が一定フレーム以上検出された後, 図\ref{fig:seen5} のシーン5へ移動する.
シーン5が表示されている間にフレーム分析処理, 動画作成処理, データ選択処理が行われており,
およそ20秒ほど処理を待機する時間が発生する.

\subsection{ユーザーインターフェースシーン6}
図\ref{fig:seen6}のシーン6はユーザーから入力を受け付けるシーンである.
点描画によって映し出されている笑顔動画データに対して順位づけを行う.
計5つ, 4回のキーボード入力を行い, 各笑顔動画データに対して順位づけデータを与える.

\subsection{ユーザーインターフェースシーン7}
図\ref{fig:seen7}のシーン7は結果表示画面であり, ユーザーの笑顔動画データを左側, 右側にユーザーが1番高く
順位づけした笑顔動画データを並列で表示する.

\subsection{ユーザーインターフェースシーン8}
図\ref{fig:seen8}のシーン8はシステム終了前のシーンである.
笑顔動画データベースおよび収集した笑顔動画データの中に含まれる全ての笑顔フレームを表示する.

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen1.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン1}
    \label{fig:seen1}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen2.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン2}
    \label{fig:seen2}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen3.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン3}
    \label{fig:seen3}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen4.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン4}
    \label{fig:seen4}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen5.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン5}
    \label{fig:seen5}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen6.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン6}
    \label{fig:seen6}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen7.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン7}
    \label{fig:seen7}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1440 900]{seen8.jpg}}
    \end{center}
    \caption{ユーザーインターフェースシーン8}
    \label{fig:seen8}
\end{figure}


\section{データ収集機能の実装}
このセクションでは, 各モジュールの実装の詳細について述べる.

\subsection{顔検出モジュールの実装}
顔検出はオープンソースであるOpenCVの中に含まれるカスケードである,
haarcascade\_frontalface\_default.xmlをOpenCVで読み込み使用する.
読み込んだ全ての動画フレームに対して顔検出の処理を行う.
\begin{itemize}
\item 顔検出検出パラメーター
\begin{lstlisting}
face_list =face_detect_cascade.detectMultiScale(
  gray,scaleFactor = 1.21,
  minNeighbors = 15,
  minSize=(300,300)
  )
\end{lstlisting}
\end{itemize}
検出した全ての動画フレームに対して表示処理を行う場合, システムのラグが発生するため,表示は偶数フレームのみとした.
返り値の画像に含まれる顔の左上のx座標およびy座標, 横幅と高さの値を次の関数へと引き継ぐ.

\subsection{笑顔検出モジュールの実装}
顔検出モジュールで得た返り値の値を参照し,顔のある領域のみに対して笑顔の検出処理を全てのフレームに対して行う.
笑顔の判別はOpenCVの中に含まれるhaarcascade\_smile.xmlを読み込み使用する.
このカスケードは顔の口の領域に対して処理を行い笑顔の検出を行う.
webカメラから取得した画像全ておよび, 全ての領域に対して笑顔検出の処理を行うことも可能であるが,
実装のテスト段階で誤検出が多かったため, 顔を検出しその中でも誤検出が一番少ないパラメータ調整を行った.

\begin{itemize}
\item 笑顔検出パラメーター
\begin{lstlisting}
smile_detector =smile_cascade.detectMultiScale(
  face_gray,scaleFactor= 1.7,
  minNeighbors=20,
  minSize=(120, 120)
  )
\end{lstlisting}
\end{itemize}

顔を検出したフレームが20フレーム以上,および笑顔を検出したフレームが5フレーム以上になった場合に
検出を終了する.

\subsection{画像処理モジュールの実装}
顔検出および笑顔検出モジュールで取得したフレームに対して, 画像処理を行う.
検出したフレームをコンパイルしたOpenFaceのFaceLandmarkImg関数を使用して, 全てのフレームから
顔のパーツの動きを表したFacial Action Unitの値をcsvファイルに算出する.
各フレームごとに生成されるため, ユーザーごとに1つのファイルにマージする処理をここで行う.

\begin{itemize}
\item OpenFace算出パラメータ例:
\begin{lstlisting}
frame, timestamp, confidence, success,
gaze_0_x, gaze_0_y, gaze_0_z, gaze_1_x, gaze_1_y, gaze_1_z,
pose_Tx, pose_Ty, pose_Tz, pose_Rx, pose_Ry, pose_Rz,
x_0, x_1, ... x_67, y_0, y_1, ..., y_67,
X_0, X_1,..., X_67, Y_0, Y_1,..., Y_67, Z_0, Z_1, ... Z_67,
p_scale, p_rx, p_ry, p_rz, p_tx, p_ty, p_0, p_1, ..., p_33,
AU01_r, AU02_r, AU04_r, AU05_r, AU06_r, AU09_r, AU10_r,
AU12_r, AU14_r, AU15_r, AU17_r, AU20_r, AU25_r, AU26_r,
AU04_c, AU12_c, AU15_c, AU23_c, AU28_c, AU45_c
\end{lstlisting}
\end{itemize}

\subsection{動画作成モジュールの実装}
フレームごとに処理をした後, 全てのフレームを時系列順に結合して笑顔動画データの作成を行う.
フレームには保存時にファイル名で時系列順に番号を振っており,　配列にデータを格納しソートすることで
時系列順に処理を行うことが可能である.
本システムにおいて,fps(Frame per Seconds) は20であったため1秒間の動画が生成される.

\subsection{データ作成モジュールの実装}
一番初めに入力したユーザーの基本データ, 画像処理モジュールで生成したCSVファイルおよび動画作成モジュール
で作成したユーザーの笑顔動画データをユーザーごとにファイリングしてデータフォーマットとする.
作成したデータは各ユーザーごと, 各データの種類ごとの2通りの方法でデータを保存する.

\begin{itemize}
\item ユーザーごとのデータツリー構造:
\dirtree{%
 .1 user\_dirname.
 .2 FAU\_data.csv(FAUから取得したデータ).
 .2 FAU\_data\_plot.png(FAUの値を簡易プロットしたグラフ画像).
 .2 user\_info.txt(ユーザーの基本情報).
 .2 rankingdata.csv(ユーザー順位づけデータ).
 .2 output.mp4(ユーザーと選んだ笑顔動画データを並べて表示).
 .2 user\_smile\_video.mp4(ユーザー単体の笑顔動画データ).
}
\end{itemize}

\subsection{笑顔動画データ選択モジュールの実装}
画像処理モジュールで生成したデータの中にあるパラメータp\_scale を使用する.
各フレームのp\_scaleを{\sl pscale\_i}とし, フレームの総数を{\sl n}とすると,
笑顔データ選択の際に使用するユーザーごとの指標user\_pcaleを以下のように定義する.
\begin{equation}
\label{pscalesum}
pscale\_sum = \sum_{i=1}^ n pscale\_i
\end{equation}

\begin{equation}
\label{userpscale}
user\_pscale= \frac{pscale\_sum}{n}
\end{equation}

p\_scaleは第\ref{chap:function}章で示した, 図\ref{fig:face_balance}の様に,
差分λで出力されるため, 各笑顔動画データのλ同士を以下のように比較演算を行う.
ユーザーの指標user\_pcale, データベースの中にある笑顔動画データそれぞれのp\_scaleの値を,
each\_pscaleとし, 差分differenceを以下のように定義する.

\begin{equation}
\label{difference}
difference =
\left(
user\_pcale - each\_pscale
\right)
^2
\end{equation}

数式\ref{difference}を各データごとにもとめ, 配列格納し昇順にソートする.
配列に格納されたデータを$x_i$と表し, 5つのデータを算出し,それぞれのデータのindexを取得する.
以下にデータを選出する際の計算式を記述する.
\begin{equation}
\label{data1}
data_1  = x_1
\end{equation}

\begin{equation}
\label{data2}
data_2 = \left\{ \begin{array}{ll}
\frac{x_{\frac{n}{2}} + x_{\frac{n+1}{2}} }{2} & (データ数が2nの場合,nは自然数) \\
x_{\frac{n}{2}} & (データ数が2n-1の場合,nは自然数)
\end{array} \right.\end{equation}

\begin{equation}
  \label{data3}
  data_3 = \left\{ \begin{array}{ll}
  \frac{x_n + x_{n+1} }{2} & (データ数が2nの場合,nは自然数) \\
  x_n & (データ数が2n-1の場合,nは自然数)
  \end{array} \right.\end{equation}

\begin{equation}
  \label{data4}
  data_4 = \left\{ \begin{array}{ll}
  \frac{x_{\frac{3n}{2}} + x_{\frac{3n+1}{2}} }{2} & (データ数が2nの場合,nは自然数) \\
  x_{\frac{3n}{2}} & (データ数が2n-1の場合,nは自然数)
  \end{array} \right.\end{equation}


\begin{equation}
  \label{data5}
  data_5  = \left\{ \begin{array}{ll}
  x_{2n} & (データ数が2nの場合,nは自然数) \\
  x_{2n-1} & (データ数が2n-1の場合,nは自然数)
  \end{array} \right.\end{equation}

数式\ref{data1}は差分の最小値,つまりユーザーの値をもつ笑顔動画データを示す.
数式\ref{data2}は,第1四分位数,数式\ref{data3}は中央値,
数式\ref{data4}は第3四分位数,数式\ref{data5}は差分の最大値をもつ笑顔動画データをそれぞれ示す.
上記の値によって取得したindexを用いて, 笑顔動画データを5種類選出する.

\subsection{表示データ作成モジュールの実装}
取得した5種類の笑顔動画データを点描画にするための処理を行う.
python のライブラリdlibを使用して顔器官検出を行う.
モデルはshape\_predictor\_68\_face\_landmarks.datを使用し, 顔の特徴点のみを表示する.

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=80mm,bb=0 0 1406 1352]{dlibfacepoits.jpg}}
    \end{center}
    \caption{dlibを用いてた特徴点検出}
    \label{fig:dlibfacepoits}
\end{figure}

\begin{figure}[htbp]
    \begin{center}
       \fbox{\includegraphics[width=140mm,bb=0 0 1733 827]{face_convert.jpg}}
    \end{center}
    \caption{変換後の動画例}
    \label{fig:face_convert}
\end{figure}

\subsection{順位づけモジュールの実装}
表示データモジュールで作成した動画データを2つずつユーザーに表示し, どちらのほうが好みかを答えてもらい
順位づけを行う. 右側を選んだ場合はR, 左を選んだ場合はLをキーボードから入力し,
選ばれなかった方の動画のpathを記録し, 次の動画を表示する.
4回比較を行い, ユーザーが最後に選んだものから逆順に1番から5番までの順位づけを行い,
それぞれの動画のpathと結びつけた状態で順位づけデータとして記録する.

\subsection{データ保存モジュールの実装}
順位づけデータを取得したのち, データベースから記録された動画pathを使用してユーザーフォルダーに
ユーザー自身のデータを除く4データを保存する. また笑顔動画を解析した結果が記録されているCSVファイルも
同時に保存し, 分析に使うデータの整理を行う.

\begin{itemize}
\item データ整理後のユーザーごとのツリー構造:
\dirtree{%
 .1 user\_dirname.
 .2 FAU\_data.csv(FAUから取得したデータ).
 .2 FAU\_data\_plot.png(FAUの値を簡易プロットしたグラフ画像).
 .2 user\_info.txt(ユーザーの基本情報).
 .2 rankingdata.csv(ユーザー順位づけデータ).
 .2 output.mp4(ユーザーと選んだ笑顔動画データを並べて表示).
 .2 user\_smile\_video.mp4(ユーザー単体の笑顔動画データ).
 .2 userFAUcsv.
 .3 AU06\_c.csv.
 .3 AU06\_r.csv.
 .3 AU07\_c.csv.
 .3 AU07\_r.csv.
 .3 AU12\_c.csv.
 .3 AU12\_r.csv.
 .3 AU25\_c.csv.
 .3 AU25\_r.csv.
 .3 merge.csv.
 .2 csvdir.
 .3 no1.csv.
 .3 no2.csv.
 .3 no3.csv.
 .3 no4.csv.
 .3 no5.csv.
 .2 videodir.
 .3 no1.mp4.
 .3 no2.mp4.
 .3 no3.mp4.
 .3 no4.mp4.
 .3 no5.mp4.
}
\end{itemize}

\subsection{選択データ表示モジュールの実装}
最後にユーザーの順位づけデータを基に, 順位づけが一番高かった笑顔動画データをユーザーの笑顔動画データ
と並べて表示する. output.mp4の動画形式で保存しユーザーが点描画で選んだ笑顔動画データの基になっている
オリジナルの動画データを表示することで, ユーザーへのフィードバックを行う.
また, 現時点では個人が特定できるような名前や年齢などパーソナルな情報は公開せずに,　笑顔動画データのみを
相手に表示する形を取っている.

\section{データ分析機能の実装}
作成中...
\subsection{FAU値計算モジュールの実装}
\subsection{データプロットモジュールの実装}
\section{まとめ}
本章では, 本システムにおけるユーザーインターフェースの実装および, データ収集機能の各モジュールの実装,
データ分析機能の各モジュールの実装についてまとめた.
次章では本研究における予備実験について述べる.
